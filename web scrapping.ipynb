{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"###Reference \n[Datacamp](https://www.datacamp.com/tutorial/web-scraping-using-python)\n\n[This](https://www.kaggle.com/discussions/getting-started/163975) link posted by @ruchi798","metadata":{"id":"WDdsPjqrK1yM"}},{"cell_type":"code","source":"# Web Scrapping with Python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"id":"owx5LLMNKrbb","execution":{"iopub.status.busy":"2022-06-09T05:52:48.985088Z","iopub.execute_input":"2022-06-09T05:52:48.985902Z","iopub.status.idle":"2022-06-09T05:52:50.013591Z","shell.execute_reply.started":"2022-06-09T05:52:48.985808Z","shell.execute_reply":"2022-06-09T05:52:50.012556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Import libraries for url manipulation\nfrom urllib.request import urlopen\nfrom bs4 import BeautifulSoup","metadata":{"id":"F-Iem84qLApk","execution":{"iopub.status.busy":"2022-06-09T05:53:12.352161Z","iopub.execute_input":"2022-06-09T05:53:12.352599Z","iopub.status.idle":"2022-06-09T05:53:12.357463Z","shell.execute_reply.started":"2022-06-09T05:53:12.352564Z","shell.execute_reply":"2022-06-09T05:53:12.35656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"url=\"https://www.nurseryrhymes.org/nursery-rhymes.html\"\nhtml=urlopen(url)","metadata":{"id":"qtEJGNjELVpN","execution":{"iopub.status.busy":"2022-06-09T05:53:15.229016Z","iopub.execute_input":"2022-06-09T05:53:15.22958Z","iopub.status.idle":"2022-06-09T05:53:16.02126Z","shell.execute_reply.started":"2022-06-09T05:53:15.229513Z","shell.execute_reply":"2022-06-09T05:53:16.020339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"soup=BeautifulSoup(html,'lxml')\ntype(soup)","metadata":{"id":"RYtS5h0VLdms","outputId":"98064117-3e28-4fda-a13e-a708ecd57b10","execution":{"iopub.status.busy":"2022-06-09T05:53:19.488513Z","iopub.execute_input":"2022-06-09T05:53:19.489228Z","iopub.status.idle":"2022-06-09T05:53:19.558614Z","shell.execute_reply.started":"2022-06-09T05:53:19.489192Z","shell.execute_reply":"2022-06-09T05:53:19.5577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the title\ntitle=soup.title\nprint(title)","metadata":{"id":"fKac1gQgLlgm","outputId":"e0b47b53-8930-459c-f00a-386d8be0c86a","execution":{"iopub.status.busy":"2022-06-09T05:53:23.070508Z","iopub.execute_input":"2022-06-09T05:53:23.070903Z","iopub.status.idle":"2022-06-09T05:53:23.076711Z","shell.execute_reply.started":"2022-06-09T05:53:23.070872Z","shell.execute_reply":"2022-06-09T05:53:23.0758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the text on webpages\ntext=soup.get_text()\nprint(soup.text)","metadata":{"id":"wHTSLumLLsKx","outputId":"ac6e679e-9abd-46c3-8ae6-bd5e217da21b","execution":{"iopub.status.busy":"2022-06-09T05:53:26.757553Z","iopub.execute_input":"2022-06-09T05:53:26.758291Z","iopub.status.idle":"2022-06-09T05:53:26.769221Z","shell.execute_reply.started":"2022-06-09T05:53:26.758254Z","shell.execute_reply":"2022-06-09T05:53:26.768396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_links=soup.find_all('td')\nall_links","metadata":{"id":"3mOsHH_Uf00z","outputId":"f78f144f-12da-48d5-9060-f28c997cf2a0","execution":{"iopub.status.busy":"2022-06-09T05:53:46.762212Z","iopub.execute_input":"2022-06-09T05:53:46.7626Z","iopub.status.idle":"2022-06-09T05:53:46.810426Z","shell.execute_reply.started":"2022-06-09T05:53:46.762562Z","shell.execute_reply":"2022-06-09T05:53:46.809498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_links=soup.find_all('a')\nlinks=[]\nfor link in all_links:\n  links.append(link.get(\"href\"))\n \nlinks\n","metadata":{"id":"KzWQuPYvM1KE","outputId":"34aa7d4c-ea0c-4426-9767-66a8177e9f6b","execution":{"iopub.status.busy":"2022-06-09T05:54:03.398568Z","iopub.execute_input":"2022-06-09T05:54:03.399436Z","iopub.status.idle":"2022-06-09T05:54:03.411416Z","shell.execute_reply.started":"2022-06-09T05:54:03.399398Z","shell.execute_reply":"2022-06-09T05:54:03.410259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first 25 and last 9 links are not useful so we have to avoid them.\nlinks_new=links[24:-9]\nprint(len(links),len(links_new))","metadata":{"id":"Ifdd9Ll0cdfG","outputId":"530aac6f-613e-435f-cfaa-0419af57fce1","execution":{"iopub.status.busy":"2022-06-09T05:54:14.764587Z","iopub.execute_input":"2022-06-09T05:54:14.764983Z","iopub.status.idle":"2022-06-09T05:54:14.769897Z","shell.execute_reply.started":"2022-06-09T05:54:14.76495Z","shell.execute_reply":"2022-06-09T05:54:14.769175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check one rhyme\nurl=\"https://www.nurseryrhymes.org/a-sailor-went-to-sea.html\"\nhtml=urlopen(url)\nsoup=BeautifulSoup(html,'lxml')\ntype(soup)","metadata":{"id":"_P8_bZVWNiuJ","outputId":"f4e05ec3-d4ba-4550-d089-c1573c508236","execution":{"iopub.status.busy":"2022-06-09T05:54:18.284679Z","iopub.execute_input":"2022-06-09T05:54:18.285423Z","iopub.status.idle":"2022-06-09T05:54:18.917545Z","shell.execute_reply.started":"2022-06-09T05:54:18.285382Z","shell.execute_reply":"2022-06-09T05:54:18.916586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rhyme words are in between <em> and </em> html tags.\n# Clean data so that all special characters and html tags are removed from rhymes\nimport re\nall_rhymes=str(soup.find('em'))\nx = all_rhymes.replace(\"<em>\", \"\")\nx=re.sub(r'(<em>|</em>|<br/>)', '', all_rhymes)\n\n#x= x.replace(\"<br/>\", \"\")\n#for link in all_links:\n#print(link.get(\"href\"))","metadata":{"id":"oYzUKSTRQUH3","execution":{"iopub.status.busy":"2022-06-09T05:54:26.366635Z","iopub.execute_input":"2022-06-09T05:54:26.367683Z","iopub.status.idle":"2022-06-09T05:54:26.373471Z","shell.execute_reply.started":"2022-06-09T05:54:26.367643Z","shell.execute_reply":"2022-06-09T05:54:26.372608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check rhyme , we will keep new line character('\\n') because it will be useful for display txt file.\nx\n","metadata":{"outputId":"aa8c81b4-5619-4dfc-82e8-38d071ed73c8","id":"Jfg2y4EGQUIR","execution":{"iopub.status.busy":"2022-06-09T05:54:30.60705Z","iopub.execute_input":"2022-06-09T05:54:30.607413Z","iopub.status.idle":"2022-06-09T05:54:30.612479Z","shell.execute_reply.started":"2022-06-09T05:54:30.607383Z","shell.execute_reply":"2022-06-09T05:54:30.611816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Open and write file in colab folder. \nf = open(\"\\Downloads\", 'w')\nwith open('sailor.txt', 'w') as f:\n    f.writelines(x)","metadata":{"id":"TrMw60OBXIKa","execution":{"iopub.status.busy":"2022-06-09T05:54:37.222276Z","iopub.execute_input":"2022-06-09T05:54:37.222647Z","iopub.status.idle":"2022-06-09T05:54:37.227898Z","shell.execute_reply.started":"2022-06-09T05:54:37.222609Z","shell.execute_reply":"2022-06-09T05:54:37.226984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Each rhyme has its own html page. So \nfor i in range(len(links_new)):\n  links_new[i]=re.sub(r'(.html)', '', links_new[i]) # Remove '.html. from links as we will be saving with link names.\n  url=\"https://www.nurseryrhymes.org/\"+ links_new[i] +\".html\" # Add '.html' here to create URL to open the link\n  print(url)  # Check each URL as you download\n  html=urlopen(url)\n  soup=BeautifulSoup(html,'lxml') # Extract url in soup object and open the file\n  all_rhymes=str(soup.find('em')) # Find <em> tags . Rhyme words are located between <em> and </em> tags here. We have to check html page by right click on the page and explore from the menu. Different values are stored under different tags.\n  x=re.sub(r'(<em>|</em>|<br/>)', '', all_rhymes)  # Remove unwanted characters(tags) from rhyme\n  f = open(\"Downloads\", 'w') \n  file=links_new[i]+'.txt' # Save rhyme as .txt file using link as name\n  with open(file, 'w') as f:\n    f.writelines(x) # copy rhyme to colab content folder\n","metadata":{"id":"KK8kAviIbVLL","outputId":"74cbfbe5-d323-4331-8683-32b3000019ec","execution":{"iopub.status.busy":"2022-06-09T05:54:41.805579Z","iopub.execute_input":"2022-06-09T05:54:41.805936Z","iopub.status.idle":"2022-06-09T05:56:49.592994Z","shell.execute_reply.started":"2022-06-09T05:54:41.805909Z","shell.execute_reply":"2022-06-09T05:56:49.59194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We cannot download directly multiple files from Colab. However, we can zip the files under the folder and then download the .zip file. Assume that we want to download all the \n#files under the sample_data folder. The first thing that we need to do is to create the zip file as follows:\n#!zip -r /content/sample_data.zip /content/\n!zip -r /kaggle/working/sample_data.zip /kaggle/working\n","metadata":{"id":"be30s7VuW-fr","outputId":"498cee98-c7b3-4045-9dab-b587e2ca57a8","execution":{"iopub.status.busy":"2022-06-09T05:59:08.191819Z","iopub.execute_input":"2022-06-09T05:59:08.19223Z","iopub.status.idle":"2022-06-09T05:59:09.006341Z","shell.execute_reply.started":"2022-06-09T05:59:08.192199Z","shell.execute_reply":"2022-06-09T05:59:09.005128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download .zip file from google colab to local drive\n#from google.colab import files\n#files.download('/content/sample_data.zip')","metadata":{"id":"duVyaL19Xdjm","outputId":"247024ad-eb76-4390-cc39-efafccc88ebb"},"execution_count":null,"outputs":[]}]}